---
title: Language?
date: 2022-02-07
---
 > We exist in the collective story of human unconsious

 pic here

 I often ponder the teleological significance of language; the [argmax](https://en.wikipedia.org/wiki/Arg_max) over the set of all grammatical functions that maximize its utility function. Language, in its most primitive form, can be thought of as a set of strings. Strings in this sense can be thought of as a sequence of symbols from a primitive set of alphabets. The set of alphabets that once modeled in a sequential manner, following the rules of said grammar, makes up the language. Language, from my perspective, seems to be a tool “created” by humans in an attempt to compress the higher dimensional abstract realm of objective reality into subjective qualia, allowing us to transfer information from one’s perspective onto another. One could think of the brain as a sort of Turing machine-based automata. This emergence of language as a quasi-compression tool is quite pivotal.

 It is often acknowledged that there was a significant alpha in having efficient means of transferring information in the form of intelligible sounds from one person to another. It was a pivotal advantage that allowed pre-historic Homo sapiens to seemingly eradicate all other hominin species we encountered, due to the fact that we were able to organize to such a high degree given the emergence of language, albeit in its most primitive form.

 If one were to take an information theory perspective, we could start with four simple questions. How many bits of information are encoded by the transmitter over the given medium given said method? how lossily compressed is said form of communication? what is the theorized maximal bitrate, or [Shannon capacity](https://en.wikipedia.org/wiki/Channel_capacity) of said medium of information propagation? and is the entropic load minimized relative to other methods?

 To ground these in more concrete classes, we could apply this set of questions to three classes of information propagation mechanisms.

 First, and most pre-historic, as noted earlier, is unintelligible sounds and gestures as a mechanism for information propagation. Let us define an architecture for a generic information propagation system as denoted by Shannon.

- Let the *source* S, be the set containing the list of states that one can conceive as letters of a primitive alphabet.
- Let the *encoder* E, be the encoding function that transforms the written or spoken message into bits of information to be transmitted.
- Let the *channel* CH, be the medium by which said encoded signal passes.
- Let *receiver* R, be the decoding function that decompresses the encoded signal to be received by the destination.
- Let the destination D, be the entity receiving said message.


<p align="center">
    ![image](https://user-images.githubusercontent.com/73560826/194781153-bc4237f3-39af-459b-8887-86a4a6bccc98.png)
</p>

> Figure 1. A primitive information propagation system

**We define**

The amount of information produced at the source by the occurence of state $s_{i} \in S$
